{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transformer from scratch: Summarizer","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport math\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-24T17:23:21.420276Z","iopub.execute_input":"2023-12-24T17:23:21.420566Z","iopub.status.idle":"2023-12-24T17:23:24.893653Z","shell.execute_reply.started":"2023-12-24T17:23:21.420540Z","shell.execute_reply":"2023-12-24T17:23:24.892722Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Processing","metadata":{}},{"cell_type":"code","source":"data = pd.read_excel('/kaggle/input/inshorts-news-data/Inshorts Cleaned Data.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:24.895434Z","iopub.execute_input":"2023-12-24T17:23:24.896232Z","iopub.status.idle":"2023-12-24T17:23:34.716659Z","shell.execute_reply.started":"2023-12-24T17:23:24.896197Z","shell.execute_reply":"2023-12-24T17:23:34.715867Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:34.717713Z","iopub.execute_input":"2023-12-24T17:23:34.718094Z","iopub.status.idle":"2023-12-24T17:23:34.751477Z","shell.execute_reply.started":"2023-12-24T17:23:34.718070Z","shell.execute_reply":"2023-12-24T17:23:34.750486Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                            Headline  \\\n0  4 ex-bank officials booked for cheating bank o...   \n1     Supreme Court to go paperless in 6 months: CJI   \n2  At least 3 killed, 30 injured in blast in Sylh...   \n3  Why has Reliance been barred from trading in f...   \n4  Was stopped from entering my own studio at Tim...   \n\n                                               Short                 Source   \\\n0  The CBI on Saturday booked four former officia...  The New Indian Express   \n1  Chief Justice JS Khehar has said the Supreme C...                 Outlook   \n2  At least three people were killed, including a...         Hindustan Times   \n3  Mukesh Ambani-led Reliance Industries (RIL) wa...                Livemint   \n4  TV news anchor Arnab Goswami has said he was t...                 YouTube   \n\n      Time  Publish Date  \n0  09:25:00   2017-03-26  \n1  22:18:00   2017-03-25  \n2  23:39:00   2017-03-25  \n3  23:08:00   2017-03-25  \n4  23:24:00   2017-03-25  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Headline</th>\n      <th>Short</th>\n      <th>Source</th>\n      <th>Time</th>\n      <th>Publish Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4 ex-bank officials booked for cheating bank o...</td>\n      <td>The CBI on Saturday booked four former officia...</td>\n      <td>The New Indian Express</td>\n      <td>09:25:00</td>\n      <td>2017-03-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Supreme Court to go paperless in 6 months: CJI</td>\n      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n      <td>Outlook</td>\n      <td>22:18:00</td>\n      <td>2017-03-25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n      <td>At least three people were killed, including a...</td>\n      <td>Hindustan Times</td>\n      <td>23:39:00</td>\n      <td>2017-03-25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why has Reliance been barred from trading in f...</td>\n      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n      <td>Livemint</td>\n      <td>23:08:00</td>\n      <td>2017-03-25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Was stopped from entering my own studio at Tim...</td>\n      <td>TV news anchor Arnab Goswami has said he was t...</td>\n      <td>YouTube</td>\n      <td>23:24:00</td>\n      <td>2017-03-25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.drop([\"Source \", \"Time \", \"Publish Date\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:34.754391Z","iopub.execute_input":"2023-12-24T17:23:34.754978Z","iopub.status.idle":"2023-12-24T17:23:34.765862Z","shell.execute_reply.started":"2023-12-24T17:23:34.754944Z","shell.execute_reply":"2023-12-24T17:23:34.764908Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:34.766830Z","iopub.execute_input":"2023-12-24T17:23:34.767119Z","iopub.status.idle":"2023-12-24T17:23:34.781123Z","shell.execute_reply.started":"2023-12-24T17:23:34.767095Z","shell.execute_reply":"2023-12-24T17:23:34.780348Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            Headline  \\\n0  4 ex-bank officials booked for cheating bank o...   \n1     Supreme Court to go paperless in 6 months: CJI   \n2  At least 3 killed, 30 injured in blast in Sylh...   \n3  Why has Reliance been barred from trading in f...   \n4  Was stopped from entering my own studio at Tim...   \n\n                                               Short  \n0  The CBI on Saturday booked four former officia...  \n1  Chief Justice JS Khehar has said the Supreme C...  \n2  At least three people were killed, including a...  \n3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n4  TV news anchor Arnab Goswami has said he was t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Headline</th>\n      <th>Short</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4 ex-bank officials booked for cheating bank o...</td>\n      <td>The CBI on Saturday booked four former officia...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Supreme Court to go paperless in 6 months: CJI</td>\n      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n      <td>At least three people were killed, including a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why has Reliance been barred from trading in f...</td>\n      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Was stopped from entering my own studio at Tim...</td>\n      <td>TV news anchor Arnab Goswami has said he was t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"inputs = data[\"Short\"].values\ntargets = data[\"Headline\"].values","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:34.782334Z","iopub.execute_input":"2023-12-24T17:23:34.782673Z","iopub.status.idle":"2023-12-24T17:23:34.790984Z","shell.execute_reply.started":"2023-12-24T17:23:34.782642Z","shell.execute_reply":"2023-12-24T17:23:34.790214Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:34.792093Z","iopub.execute_input":"2023-12-24T17:23:34.792415Z","iopub.status.idle":"2023-12-24T17:23:37.866266Z","shell.execute_reply.started":"2023-12-24T17:23:34.792379Z","shell.execute_reply":"2023-12-24T17:23:37.865308Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37f7a64dcdb047319225953f8db16a05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65cb9dff81254503a4b805d059756f60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf768c5883344f3ab4a1849a9d55682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e0ac1eaea834014a4112357aba77754"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode(\"Hello There\"), skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:37.867506Z","iopub.execute_input":"2023-12-24T17:23:37.867921Z","iopub.status.idle":"2023-12-24T17:23:47.667763Z","shell.execute_reply.started":"2023-12-24T17:23:37.867895Z","shell.execute_reply":"2023-12-24T17:23:47.666839Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'Hello There'"},"metadata":{}}]},{"cell_type":"code","source":"vocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:47.669069Z","iopub.execute_input":"2023-12-24T17:23:47.669755Z","iopub.status.idle":"2023-12-24T17:23:47.674232Z","shell.execute_reply.started":"2023-12-24T17:23:47.669719Z","shell.execute_reply":"2023-12-24T17:23:47.673312Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"inputs[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:47.677568Z","iopub.execute_input":"2023-12-24T17:23:47.677841Z","iopub.status.idle":"2023-12-24T17:23:47.714779Z","shell.execute_reply.started":"2023-12-24T17:23:47.677817Z","shell.execute_reply":"2023-12-24T17:23:47.713888Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode(inputs[0]), skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:47.715780Z","iopub.execute_input":"2023-12-24T17:23:47.716019Z","iopub.status.idle":"2023-12-24T17:23:47.729842Z","shell.execute_reply.started":"2023-12-24T17:23:47.715998Z","shell.execute_reply":"2023-12-24T17:23:47.728989Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state - run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.'"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenizer.encode(list(inputs)[0]))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:47.730924Z","iopub.execute_input":"2023-12-24T17:23:47.731272Z","iopub.status.idle":"2023-12-24T17:23:47.742157Z","shell.execute_reply.started":"2023-12-24T17:23:47.731247Z","shell.execute_reply":"2023-12-24T17:23:47.741338Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[101, 1109, 18893, 2240, 1113, 4306, 18951, 1300, 1393, 3878, 1104, 25139, 2950, 1105, 1565, 1639, 1111, 18661, 117, 26621, 1616, 117, 4771, 10758, 1105, 3989, 838, 10973, 1580, 24809, 2445, 1106, 1103, 1352, 118, 1576, 3085, 119, 1109, 4806, 1125, 28057, 1174, 1313, 11453, 1105, 4755, 1121, 25139, 2950, 1113, 1103, 3142, 1104, 17667, 1105, 27615, 4961, 119, 1636, 4381, 1127, 10258, 16564, 1193, 3175, 1106, 1103, 2557, 2205, 1118, 1103, 4806, 4983, 119, 102]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode(tokenizer(list(inputs[:5]))[\"input_ids\"][4])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:47.743285Z","iopub.execute_input":"2023-12-24T17:23:47.743574Z","iopub.status.idle":"2023-12-24T17:23:47.756584Z","shell.execute_reply.started":"2023-12-24T17:23:47.743550Z","shell.execute_reply":"2023-12-24T17:23:47.755705Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'[CLS] TV news anchor Arnab Goswami has said he was told he could not do the programme two days before leaving Times Now. & # 34 ; 18th November was my last day, I was not allowed to enter my own studio, & # 34 ; Goswami added. & # 34 ; When you build an institution and are not allowed to enter your own studio, you feel sad, & # 34 ; the journalist further said. [SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"inputs = tokenizer(list(inputs), return_tensors=\"pt\", padding=True)[\"input_ids\"]\ntargets = tokenizer(list(targets), return_tensors=\"pt\", padding=True)[\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:23:47.757746Z","iopub.execute_input":"2023-12-24T17:23:47.758340Z","iopub.status.idle":"2023-12-24T17:24:11.770763Z","shell.execute_reply.started":"2023-12-24T17:23:47.758314Z","shell.execute_reply":"2023-12-24T17:24:11.769903Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"max_inp_len = max(len(i) for i in inputs)\nmax_targ_len = max(len(i) for i in targets)\n\nmax_inp_len, max_targ_len","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:11.771914Z","iopub.execute_input":"2023-12-24T17:24:11.772224Z","iopub.status.idle":"2023-12-24T17:24:12.117352Z","shell.execute_reply.started":"2023-12-24T17:24:11.772198Z","shell.execute_reply":"2023-12-24T17:24:12.116360Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(184, 42)"},"metadata":{}}]},{"cell_type":"code","source":"inputs[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.118401Z","iopub.execute_input":"2023-12-24T17:24:12.118668Z","iopub.status.idle":"2023-12-24T17:24:12.134503Z","shell.execute_reply.started":"2023-12-24T17:24:12.118645Z","shell.execute_reply":"2023-12-24T17:24:12.133547Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  1109, 18893,  2240,  1113,  4306, 18951,  1300,  1393,  3878,\n         1104, 25139,  2950,  1105,  1565,  1639,  1111, 18661,   117, 26621,\n         1616,   117,  4771, 10758,  1105,  3989,   838, 10973,  1580, 24809,\n         2445,  1106,  1103,  1352,   118,  1576,  3085,   119,  1109,  4806,\n         1125, 28057,  1174,  1313, 11453,  1105,  4755,  1121, 25139,  2950,\n         1113,  1103,  3142,  1104, 17667,  1105, 27615,  4961,   119,  1636,\n         4381,  1127, 10258, 16564,  1193,  3175,  1106,  1103,  2557,  2205,\n         1118,  1103,  4806,  4983,   119,   102,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0])"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(inputs[0], skip_special_tokens=True), tokenizer.decode(targets[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.135603Z","iopub.execute_input":"2023-12-24T17:24:12.135937Z","iopub.status.idle":"2023-12-24T17:24:12.144459Z","shell.execute_reply.started":"2023-12-24T17:24:12.135906Z","shell.execute_reply":"2023-12-24T17:24:12.143652Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"('The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state - run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.',\n '4 ex - bank officials booked for cheating bank of ₹209 crore')"},"metadata":{}}]},{"cell_type":"code","source":"len(inputs), len(targets)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.145508Z","iopub.execute_input":"2023-12-24T17:24:12.145750Z","iopub.status.idle":"2023-12-24T17:24:12.153564Z","shell.execute_reply.started":"2023-12-24T17:24:12.145728Z","shell.execute_reply":"2023-12-24T17:24:12.152689Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(55104, 55104)"},"metadata":{}}]},{"cell_type":"code","source":"train_inputs = inputs[:int(0.8 * len(inputs))]\ntrain_targets = targets[:int(0.8 * len(targets))]\n\nval_inputs = inputs[int(0.8 * len(inputs)):int(0.9*len(inputs))]\nval_targets = targets[int(0.8 * len(targets)):int(0.9*len(targets))]\n\ntest_inputs = inputs[int(0.9 * len(inputs)):]\ntest_targets = targets[int(0.9 * len(targets)):]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.154951Z","iopub.execute_input":"2023-12-24T17:24:12.155229Z","iopub.status.idle":"2023-12-24T17:24:12.169768Z","shell.execute_reply.started":"2023-12-24T17:24:12.155206Z","shell.execute_reply":"2023-12-24T17:24:12.168953Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class NewsSummaryDataset(Dataset):\n    def __init__(self, inp, targ):\n        self.inp = inp\n        self.targ = targ\n        \n    def __len__(self): return len(self.inp)\n    \n    def __getitem__(self, idx):\n        return self.inp[idx], self.targ[idx]\n    \n    def decode(self, idx):\n        decoded_inp = tokenizer.decode(self.inp[idx], skip_special_tokens=True)\n        decoded_targ = tokenizer.decode(self.targ[idx], skip_special_tokens=True)\n        return decoded_inp, decoded_targ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.170910Z","iopub.execute_input":"2023-12-24T17:24:12.171188Z","iopub.status.idle":"2023-12-24T17:24:12.179855Z","shell.execute_reply.started":"2023-12-24T17:24:12.171164Z","shell.execute_reply":"2023-12-24T17:24:12.179006Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataset = NewsSummaryDataset(train_inputs, train_targets)\nval_dataset = NewsSummaryDataset(val_inputs, val_targets)\ntest_dataset = NewsSummaryDataset(test_inputs, test_targets)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.180973Z","iopub.execute_input":"2023-12-24T17:24:12.181291Z","iopub.status.idle":"2023-12-24T17:24:12.193502Z","shell.execute_reply.started":"2023-12-24T17:24:12.181267Z","shell.execute_reply":"2023-12-24T17:24:12.192742Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"len(train_dataset), len(val_dataset), len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.194488Z","iopub.execute_input":"2023-12-24T17:24:12.194763Z","iopub.status.idle":"2023-12-24T17:24:12.207315Z","shell.execute_reply.started":"2023-12-24T17:24:12.194740Z","shell.execute_reply":"2023-12-24T17:24:12.206483Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(44083, 5510, 5511)"},"metadata":{}}]},{"cell_type":"code","source":"print(train_dataset.decode(-1))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.208474Z","iopub.execute_input":"2023-12-24T17:24:12.208736Z","iopub.status.idle":"2023-12-24T17:24:12.217997Z","shell.execute_reply.started":"2023-12-24T17:24:12.208714Z","shell.execute_reply":"2023-12-24T17:24:12.217186Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"('Nepali Rescuers on Monday abandoned the mission to recover the bodies of two Indian climbers from the Mount Everest. The two men, Paresh Nath and Goutam Ghosh, went missing on May 21 and their bodies were later located near the 8000 - metre height, which marks the beginning of the & # 39 ; death zone & # 39 ;. Another mountaineer, Subhash Pal, had earlier died during his descent.', 'Mission to get Indian climbers & # 39 ; bodies abandoned')\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.219119Z","iopub.execute_input":"2023-12-24T17:24:12.219378Z","iopub.status.idle":"2023-12-24T17:24:12.230365Z","shell.execute_reply.started":"2023-12-24T17:24:12.219355Z","shell.execute_reply":"2023-12-24T17:24:12.229433Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"def pad_sequence(batch):\n    inp_seqs = [inp for inp, targs in batch]\n    targ_seqs = [targs for inp, targs in batch]\n    \n    inp_padded = torch.nn.utils.rnn.pad_sequence(torch.tensor(inp_seqs), batch_first=True, padding_value=tokenizer.pad_token_id)\n    targ_padded = torch.nn.utils.rnn.pad_sequence(torch.tensor(targ_seqs), batch_first=True, padding_value=tokenizer.pad_token_id)\n    \n    return inp_padded, targ_padded","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.231483Z","iopub.execute_input":"2023-12-24T17:24:12.231734Z","iopub.status.idle":"2023-12-24T17:24:12.240876Z","shell.execute_reply.started":"2023-12-24T17:24:12.231712Z","shell.execute_reply":"2023-12-24T17:24:12.239928Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\n\nclass Dataloaders:\n    def __init__(self):\n        self.train_dataset = NewsSummaryDataset(train_inputs, train_targets)\n        self.valid_dataset = NewsSummaryDataset(val_inputs, val_targets)\n        self.test_dataset = NewsSummaryDataset(test_inputs, test_targets)\n        \n        self.train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n        self.valid_loader = DataLoader(self.valid_dataset, batch_size=batch_size, shuffle=True)\n        self.test_loader = DataLoader(self.test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.242321Z","iopub.execute_input":"2023-12-24T17:24:12.242644Z","iopub.status.idle":"2023-12-24T17:24:12.252672Z","shell.execute_reply.started":"2023-12-24T17:24:12.242615Z","shell.execute_reply":"2023-12-24T17:24:12.251892Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Transformers Architecture","metadata":{}},{"cell_type":"code","source":"class MultiHeadedAttention(nn.Module):\n    def __init__(self, h, d_embed, dropout=0.0):\n        super(MultiHeadedAttention, self).__init__()\n        assert d_embed % h == 0 # check the h number\n        self.d_k = d_embed//h\n        self.d_embed = d_embed\n        self.h = h\n        self.WQ = nn.Linear(d_embed, d_embed)\n        self.WK = nn.Linear(d_embed, d_embed)\n        self.WV = nn.Linear(d_embed, d_embed)\n        self.linear = nn.Linear(d_embed, d_embed)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x_query, x_key, x_value, mask=None):\n        nbatch = x_query.size(0) # get batch size\n        # 1) Linear projections to get the multi-head query, key and value tensors\n        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n        # 2) Attention\n        # scores has dimensions: nbatch * h * seq_len * seq_len\n        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n        # 3) Mask out padding tokens and future tokens\n        if mask is not None:\n            scores = scores.masked_fill(mask, float('-inf'))\n        # p_atten dimensions: nbatch * h * seq_len * seq_len\n        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n        p_atten = self.dropout(p_atten)\n        # x dimensions: nbatch * h * seq_len * d_k\n        x = torch.matmul(p_atten, value)\n        # x now has dimensions:nbtach * seq_len * d_embed\n        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n        return self.linear(x) # final linear layer","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.253722Z","iopub.execute_input":"2023-12-24T17:24:12.253977Z","iopub.status.idle":"2023-12-24T17:24:12.265432Z","shell.execute_reply.started":"2023-12-24T17:24:12.253955Z","shell.execute_reply":"2023-12-24T17:24:12.264717Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class ResidualConnection(nn.Module):\n    '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n    def __init__(self, dim, dropout):\n        super().__init__()\n        self.drop = nn.Dropout(dropout)\n        self.norm = nn.LayerNorm(dim)\n\n    def forward(self, x, sublayer):\n        return x + self.drop(sublayer(self.norm(x)))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.270619Z","iopub.execute_input":"2023-12-24T17:24:12.270959Z","iopub.status.idle":"2023-12-24T17:24:12.279744Z","shell.execute_reply.started":"2023-12-24T17:24:12.270924Z","shell.execute_reply":"2023-12-24T17:24:12.278873Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n    def __init__(self, config):\n        super().__init__()\n        self.d_embed = config.d_embed\n        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) \n        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_inp_len, config.d_embed)) \n        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n        self.dropout = nn.Dropout(config.dropout)\n        self.norm = nn.LayerNorm(config.d_embed)\n\n    def forward(self, input, mask=None):\n        x = self.tok_embed(input)\n        x_pos = self.pos_embed[:, :x.size(1), :]\n        x = self.dropout(x + x_pos)\n        for layer in self.encoder_blocks:\n            x = layer(x, mask)\n        return self.norm(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.280749Z","iopub.execute_input":"2023-12-24T17:24:12.281044Z","iopub.status.idle":"2023-12-24T17:24:12.295177Z","shell.execute_reply.started":"2023-12-24T17:24:12.281007Z","shell.execute_reply":"2023-12-24T17:24:12.294397Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n    def __init__(self, config):\n        super(EncoderBlock, self).__init__()\n        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n        self.feed_forward = nn.Sequential(\n            nn.Linear(config.d_embed, config.d_ff),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(config.d_ff, config.d_embed)\n        )\n        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n\n    def forward(self, x, mask=None):\n        # self-attention\n        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n        # position-wise fully connected feed-forward layer\n        return self.residual2(x, self.feed_forward)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.296334Z","iopub.execute_input":"2023-12-24T17:24:12.296664Z","iopub.status.idle":"2023-12-24T17:24:12.306346Z","shell.execute_reply.started":"2023-12-24T17:24:12.296629Z","shell.execute_reply":"2023-12-24T17:24:12.305499Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n    def __init__(self, config):\n        super().__init__()\n        self.d_embed = config.d_embed\n        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_targ_len, config.d_embed)) \n        self.dropout = nn.Dropout(config.dropout)\n        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n        self.norm = nn.LayerNorm(config.d_embed)\n        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n    \n    def future_mask(self, seq_len):\n        '''mask out tokens at future positions'''\n        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(device)\n        return mask.view(1, 1, seq_len, seq_len)\n\n    def forward(self, memory, src_mask, trg, trg_pad_mask):\n        seq_len = trg.size(1)\n        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n        x = self.dropout(x)\n        for layer in self.decoder_blocks:\n            x = layer(memory, src_mask, x, trg_mask)\n        x = self.norm(x)\n        logits = self.linear(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.307398Z","iopub.execute_input":"2023-12-24T17:24:12.307721Z","iopub.status.idle":"2023-12-24T17:24:12.322049Z","shell.execute_reply.started":"2023-12-24T17:24:12.307691Z","shell.execute_reply":"2023-12-24T17:24:12.321093Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n    def __init__(self, config):\n        super().__init__()\n        self.atten1 = MultiHeadedAttention(config.h, config.d_embed)\n        self.atten2 = MultiHeadedAttention(config.h, config.d_embed)\n        self.feed_forward = nn.Sequential(\n            nn.Linear(config.d_embed, config.d_ff),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(config.d_ff, config.d_embed)\n        )\n        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout) \n                                       for i in range(3)])\n\n    def forward(self, memory, src_mask, decoder_layer_input, trg_mask):\n        x = memory\n        y = decoder_layer_input\n        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask))\n        # keys and values are from the encoder output\n        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n        return self.residuals[2](y, self.feed_forward)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.323143Z","iopub.execute_input":"2023-12-24T17:24:12.323420Z","iopub.status.idle":"2023-12-24T17:24:12.337873Z","shell.execute_reply.started":"2023-12-24T17:24:12.323397Z","shell.execute_reply":"2023-12-24T17:24:12.336970Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src, src_mask, trg, trg_pad_mask):\n        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.339085Z","iopub.execute_input":"2023-12-24T17:24:12.339367Z","iopub.status.idle":"2023-12-24T17:24:12.352893Z","shell.execute_reply.started":"2023-12-24T17:24:12.339344Z","shell.execute_reply":"2023-12-24T17:24:12.351957Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass ModelConfig:\n    encoder_vocab_size: int\n    decoder_vocab_size: int\n    d_embed: int\n    # d_ff is the dimension of the fully-connected  feed-forward layer\n    d_ff: int\n    # h is the number of attention head\n    h: int\n    N_encoder: int\n    N_decoder: int\n    max_inp_len: int\n    max_targ_len: int\n    dropout: float\n        \ndef make_model(config):\n    model = Transformer(Encoder(config), Decoder(config)).to(device)\n    \n    for p in model.parameters():\n        if p.dim() > 1: nn.init.xavier_uniform_(p)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.353954Z","iopub.execute_input":"2023-12-24T17:24:12.354251Z","iopub.status.idle":"2023-12-24T17:24:12.365219Z","shell.execute_reply.started":"2023-12-24T17:24:12.354228Z","shell.execute_reply":"2023-12-24T17:24:12.364440Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def make_batch_input(x, y):\n        src = x.to(device)\n        trg_in = y[:, :-1].to(device)\n        trg_out = y[:, 1:].contiguous().view(-1).to(device)\n        src_pad_mask = (src == tokenizer.pad_token_id).view(src.size(0), 1, 1, src.size(-1))\n        trg_pad_mask = (trg_in == tokenizer.pad_token_id).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.366248Z","iopub.execute_input":"2023-12-24T17:24:12.366503Z","iopub.status.idle":"2023-12-24T17:24:12.376146Z","shell.execute_reply.started":"2023-12-24T17:24:12.366481Z","shell.execute_reply":"2023-12-24T17:24:12.375279Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from numpy.lib.utils import lookfor\ndef train_epoch(model, dataloaders):\n    model.train()\n    grad_norm_clip = 1.0\n    losses, acc, count = [], 0, 0\n    num_batches = len(dataloaders.train_loader)\n    pbar = tqdm(enumerate(dataloaders.train_loader), total=num_batches)\n    for idx, (x, y)  in  pbar:\n        optimizer.zero_grad()\n        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(device)\n        pred = pred.view(-1, pred.size(-1))\n        loss = loss_fn(pred, trg_out).to(device)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n        optimizer.step()\n        scheduler.step()\n        losses.append(loss.item())\n        # report progress\n        if idx>0 and idx%50 == 0:\n            pbar.set_description(f'train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}')\n    return np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.377152Z","iopub.execute_input":"2023-12-24T17:24:12.377403Z","iopub.status.idle":"2023-12-24T17:24:12.392149Z","shell.execute_reply.started":"2023-12-24T17:24:12.377381Z","shell.execute_reply":"2023-12-24T17:24:12.391299Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloaders, epochs):\n    global early_stop_count\n    best_valid_loss = float('inf')\n    train_size = len(dataloaders.train_loader)*batch_size\n    for ep in range(epochs):\n        train_loss = train_epoch(model, dataloaders)\n        valid_loss = validate(model, dataloaders.valid_loader)\n        \n        print(f'ep: {ep}: train_loss={train_loss:.5f}, valid_loss={valid_loss:.5f}')\n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n        else:\n            if scheduler.last_epoch>2*warmup_steps:\n                early_stop_count -= 1\n                if early_stop_count<=0:   \n                    return train_loss, valid_loss\n    return train_loss, valid_loss","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.393122Z","iopub.execute_input":"2023-12-24T17:24:12.393399Z","iopub.status.idle":"2023-12-24T17:24:12.403227Z","shell.execute_reply.started":"2023-12-24T17:24:12.393376Z","shell.execute_reply":"2023-12-24T17:24:12.402452Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloder):\n    'compute the validation loss'\n    model.eval()\n    losses = []\n    with torch.no_grad():\n        for i, (x, y) in enumerate(dataloder):\n            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(device)\n            pred = pred.view(-1, pred.size(-1))\n            losses.append(loss_fn(pred, trg_out).item())\n    return np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.404231Z","iopub.execute_input":"2023-12-24T17:24:12.404487Z","iopub.status.idle":"2023-12-24T17:24:12.418308Z","shell.execute_reply.started":"2023-12-24T17:24:12.404464Z","shell.execute_reply":"2023-12-24T17:24:12.417586Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"config = ModelConfig(encoder_vocab_size = vocab_size, \n                     decoder_vocab_size=vocab_size,\n                     d_embed=512, \n                     d_ff=512, \n                     h=8,\n                     N_encoder=3, \n                     N_decoder=3,\n                     max_inp_len=max_inp_len,\n                     max_targ_len=max_targ_len,\n                     dropout=0.1\n                     )\n\ndata_loaders = Dataloaders()\ntrain_size = len(data_loaders.train_loader)*batch_size\nmodel = make_model(config)\nmodel_size = sum([p.numel() for p in model.parameters()])\nprint(f'model_size: {model_size}, train_set_size: {train_size}')\nwarmup_steps = 3*len(data_loaders.train_loader)\n# lr first increases in the warmup steps, and then descreases\nlr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\noptimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\nloss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\nearly_stop_count = 2\ntrain_loss, valid_loss = train(model, data_loaders, epochs=20)\ntest_loss  = validate(model, data_loaders.test_loader)\n\nprint(f'train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, test_loss: {test_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:24:12.419463Z","iopub.execute_input":"2023-12-24T17:24:12.420267Z","iopub.status.idle":"2023-12-24T17:41:12.607634Z","shell.execute_reply.started":"2023-12-24T17:24:12.420241Z","shell.execute_reply":"2023-12-24T17:41:12.606656Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"model_size: 57307460, train_set_size: 44160\n","output_type":"stream"},{"name":"stderr","text":"train loss=5.943, lr=0.00020: 100%|██████████| 345/345 [02:02<00:00,  2.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 0: train_loss=7.47125, valid_loss=5.85477\n","output_type":"stream"},{"name":"stderr","text":"train loss=4.801, lr=0.00043: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 1: train_loss=5.08997, valid_loss=4.62783\n","output_type":"stream"},{"name":"stderr","text":"train loss=3.920, lr=0.00066: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 2: train_loss=3.97905, valid_loss=4.02508\n","output_type":"stream"},{"name":"stderr","text":"train loss=3.008, lr=0.00060: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 3: train_loss=3.18125, valid_loss=3.73937\n","output_type":"stream"},{"name":"stderr","text":"train loss=2.612, lr=0.00054: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 4: train_loss=2.49379, valid_loss=3.63194\n","output_type":"stream"},{"name":"stderr","text":"train loss=2.141, lr=0.00049: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 5: train_loss=1.96807, valid_loss=3.65521\n","output_type":"stream"},{"name":"stderr","text":"train loss=1.637, lr=0.00045: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 6: train_loss=1.55578, valid_loss=3.80485\n","output_type":"stream"},{"name":"stderr","text":"train loss=1.197, lr=0.00042: 100%|██████████| 345/345 [02:01<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ep: 7: train_loss=1.22980, valid_loss=3.91893\ntrain_loss: 1.2298, valid_loss: 3.9189, test_loss: 4.1524\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"def summarize(model, x):\n    with torch.inference_mode():\n        dB = test_inp_b.size(0)\n        y = torch.tensor([[tokenizer.cls_token_id] * dB]).view(dB, 1).to(device)\n        x_pad_mask = (x == tokenizer.pad_token_id).view(x.size(0), 1, 1, x.size(-1)).to(device)\n        memory = model.encoder(x.to(device), x_pad_mask).to(device)\n        for i in range(max_targ_len):\n            y_pad_mask = (y == tokenizer.pad_token_id).view(y.size(0), 1, 1, y.size(-1)).to(device)\n            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n            last_output = logits.argmax(-1)[:, -1]\n            last_output = last_output.view(dB, 1)\n            y = torch.cat((y, last_output), 1).to(device)\n    return y","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:41:12.608931Z","iopub.execute_input":"2023-12-24T17:41:12.609268Z","iopub.status.idle":"2023-12-24T17:41:12.617650Z","shell.execute_reply.started":"2023-12-24T17:41:12.609242Z","shell.execute_reply":"2023-12-24T17:41:12.616658Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test_inp_b, test_targ_b = next(iter(data_loaders.test_loader))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:47:10.626910Z","iopub.execute_input":"2023-12-24T17:47:10.627291Z","iopub.status.idle":"2023-12-24T17:47:10.634565Z","shell.execute_reply.started":"2023-12-24T17:47:10.627259Z","shell.execute_reply":"2023-12-24T17:47:10.633548Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"y_preds = summarize(model, test_inp_b)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:47:17.997309Z","iopub.execute_input":"2023-12-24T17:47:17.998159Z","iopub.status.idle":"2023-12-24T17:47:19.518040Z","shell.execute_reply.started":"2023-12-24T17:47:17.998125Z","shell.execute_reply":"2023-12-24T17:47:19.517084Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print(\"Original - {}\\nSummary - {}\\n\\n\".format(tokenizer.decode(test_inp_b[i], skip_special_tokens=True), tokenizer.decode(y_preds[i], skip_special_tokens=True)))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:47:20.470846Z","iopub.execute_input":"2023-12-24T17:47:20.471723Z","iopub.status.idle":"2023-12-24T17:47:20.480842Z","shell.execute_reply.started":"2023-12-24T17:47:20.471686Z","shell.execute_reply":"2023-12-24T17:47:20.479872Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Original - India registered a nine - wicket victory over the UAE with 59 balls remaining in the Asia Cup on Thursday, making this India & # 39 ; s largest T20I victory in terms of balls remaining. India achieved the target of 82 runs riding on Rohit Sharma & # 39 ; s 39 ( 28 ) and Yuvraj Singh & # 39 ; s 25 ( 14 ). India will now face - off against Bangladesh in the Asia Cup final on Sunday.\nSummary - India register their largest Asia Cup - finals\n\n\nOriginal - Singer Sonu Nigam, while travelling on a flight from Jodhpur to Mumbai recently, surprised all the passengers with an impromptu performance. The 42 - year - old singer went up to the instructor & # 39 ; s microphone on the plane and started humming the song & # 39 ; Do Pal & # 39 ; from the film & # 39 ; Veer Zaara & # 39 ; ( 2004 ). A video of his performance has garnered over 7, 000 likes on Facebook.\nSummary - Nithari performs on Drpil Jodhpur & # 39 ; s attempt\n\n\nOriginal - The Supreme Court on Monday questioned certain states such as Maharashtra, Karnataka and Gujarat among others for not implementing schemes like MGNREGA, National Food Security and mid - day meal in drought - hit areas. The apex court had earlier asked the Centre to update it about the implementation of the schemes to identify whether the affected receive minimum employment and food, or not.\nSummary - SC questions Maha, Gujarat, Gujarat, Gujarat, Gujarat : SC questions Centre\n\n\nOriginal - On the day of the US Presidential electoral debate in Iowa, # IowaCaucus was a global Twitter trend on Tuesday. Whistleblower Edward Snowden tweeted, & # 34 ; It turns out money decides elections after all. # IowaCaucus & # 34 ; referring to Hillary Clinton & # 39 ; s narrow win over Bernie Sanders. Users trolled Donald Trump after Ted Cruz & # 39 ; s victory tweeting, & # 34 ; Hey @ realDonaldTrump, & # 34 ; You & # 39 ; re Fired! & # 34 ; # IowaCaucus & # 34 ;.\nSummary - Twitter reacts to US & # 39 ; The Wall Street & # 39 ; in US\n\n\nOriginal - Manchester City thrashed Aston Villa 4 - 0 in the fourth round of the FA Cup at Villa Park on Saturday to advance to the last 16 of the tournament. Kelechi Iheanacho netted his first senior hat - trick for City while Raheem Sterling added the fourth goal. Notably, Aston Villa were last year & # 39 ; s FA Cup finalists.\nSummary - New Zealand thrash shooting 4 - 0 at 16 - 0\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Saving the Model","metadata":{}},{"cell_type":"code","source":"torch.save(model, 'transformer_summarizer.pth')\ntorch.save(model.state_dict(), 'transformer_summarizer_params.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T17:48:23.024122Z","iopub.execute_input":"2023-12-24T17:48:23.024984Z","iopub.status.idle":"2023-12-24T17:48:23.869381Z","shell.execute_reply.started":"2023-12-24T17:48:23.024947Z","shell.execute_reply":"2023-12-24T17:48:23.868563Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}